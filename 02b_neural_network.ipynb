{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02b_neural_network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNU2LcfwcY9v7a2WJBJjIma",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antounes/practical-ml-for-computer-vision/blob/main/02b_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Flowers Image Classification Using a Neural Network"
      ],
      "metadata": {
        "id": "b4HHcfwkA2J1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enable GPU and set up helper functions "
      ],
      "metadata": {
        "id": "wsw1B31NBmkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.version.VERSION)\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print('GPU device not found - On for CPU time!')\n",
        "else:\n",
        "  print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "id": "7ZflwUsIBsSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper functions\n",
        "\n",
        "def training_plot(metrics, history):\n",
        "  f, ax = plt.subplots(1, len(metrics), figsize=(5*len(metrics), 5))\n",
        "  for idx, metric in enumerate(metrics):\n",
        "    ax[idx].plot(history.history[metric], ls='dashed')\n",
        "    ax[idx].set_xlabel('Epochs')\n",
        "    ax[idx].set_ylabel(metric)\n",
        "    ax[idx].plot(history.history['val_'+metric]);\n",
        "    ax[idx].legend(['train_'+metric, 'val_'+metric])\n",
        "\n",
        "# Call model.predict() on a few images in the evaluation dataset\n",
        "\n",
        "def plot_predicitons(filename):\n",
        "  f, ax = plt.subplots(3, 5, figsize=(25, 15))\n",
        "  dataset = tf.data.TextLineDataset(filename).map(decode_csv)\n",
        "  for idx, (img, label) in enumerate(dataset.take(15)):\n",
        "    ax[idx//5, idx%5].imshow(img.numpy());\n",
        "    batch_image = tf.reshape(img, [1, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS])\n",
        "    batch_pred = model.predict(batch_image)\n",
        "    pred = batch_pred[0]\n",
        "    label = CLASS_NAMES(label.numpy())\n",
        "    pred_label_index = tf.math.argmax(pred).numpy()\n",
        "    pred_label = CLASS_NAMES[pred_label_index]\n",
        "    prob = pred[pred_label_index]\n",
        "    ax[idx//5, idx%5].set_title('{}: {} ({:.4f})'.format(label, pred_label, prob))\n",
        "\n",
        "def show_trained_weights(model):\n",
        "  # CLASS_NAMES is ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n",
        "  LAYER = 1 # Layer 0 flattens the image, layer=1 is the first dense layer\n",
        "  WEIGHT_TYPE = 0 # 0 for weight, 1 for bias\n",
        "\n",
        "  f, ax = plt.subplots(1, 5, figsize=(15, 15))\n",
        "  for flower in range(len(CLASS_NAMES)):\n",
        "    weights = model.layers[LAYER].get_weights()[WEIGHT_TYPE][:, flower]\n",
        "    min_wt = tf.math.reduce_min(weights).numpy()\n",
        "    max_wt = tf.math.reduce_max(weights).numpy()\n",
        "    flower_name = CLASS_NAMES[flower]\n",
        "    print('Scaling weights for {} in {} to {}'.format(flower_name, min_wt, max_wt))\n",
        "    weights = (weights - min_wt) / (max_wt - min_wt)\n",
        "    ax[flower].ishow(weights.reshape(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS));\n",
        "    ax[flower].set_title(flower_name);"
      ],
      "metadata": {
        "id": "37IImnPNBsZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "IMG_CHANNELS = 3\n",
        "\n",
        "def read_and_decode(filename, reshape_dims):\n",
        "  # Read the file\n",
        "  img = tf.io.read_file(filename)\n",
        "  # Convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img, channels=IMG_CHANNELS)\n",
        "  # Use `convert_image_dtype` to convert to floats in the [0, 1] range\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "  # Resize the image to the desired size\n",
        "  return tf.image.resize(img, reshape_dims)\n",
        "\n",
        "CLASS_NAMES = [item.numpy().decode('utf8') \n",
        "for item in tf.strings.regex_replace(tf.io.gfile.glob('gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/*'), \n",
        "                                     'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/', '')\n",
        "]\n",
        "CLASS_NAMES = [item for item in CLASS_NAMES if item.find('.')==-1]\n",
        "print('These are the available classes:', CLASS_NAMES)\n",
        "\n",
        "# The label is the index into CLASS_NAMES array\n",
        "def decode_csv(csv_row):\n",
        "  record_defaults = ['path', 'flower']\n",
        "  filename, label_string = tf.io.decode_csv(csv_row, record_defaults)\n",
        "  img = read_and_decode(filename, [IMG_HEIGHT, IMG_WIDTH])\n",
        "  label = tf.argmax(tf.math.equal(CLASS_NAMES, label_string))\n",
        "  return img, label"
      ],
      "metadata": {
        "id": "PeXy9PEdBsd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A Neural Network Model"
      ],
      "metadata": {
        "id": "D7q03tzkDYWR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the neural network"
      ],
      "metadata": {
        "id": "uTzJuLFZyRWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding one non-linear layer in the middle\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataset = tf.data.TextLineDataset(\n",
        "    'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/train_set.csv'\n",
        ").map(decode_csv).batch(BATCH_SIZE)\n",
        "\n",
        "eval_dataset = tf.data.TextLineDataset(\n",
        "    'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/eval_set.csv'\n",
        ").map(decode_csv).batch(BATCH_SIZE)\n",
        "\n",
        "# Neural network with one hidden layer\n",
        "model = tf.keras.Sequential([\n",
        "          tf.keras.layers.Flatten(input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)),\n",
        "          tf.keras.layers.Dense(units=128, activation='relu'),\n",
        "          tf.keras.layers.Dense(units=len(CLASS_NAMES), activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(train_dataset, validation_data=eval_dataset, epochs=10)"
      ],
      "metadata": {
        "id": "_t3SVL5bGtMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_plot(['loss', 'accuracy'], history)"
      ],
      "metadata": {
        "id": "GXcg9y35Gty-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Learning rate"
      ],
      "metadata": {
        "id": "wNXI-V5NylJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# parametrise to the values in the previous cell\n",
        "\n",
        "def train_and_evaluate(batch_size=32,\n",
        "                       lrate=0.001, # default learning rate in Adam constructor\n",
        "                       l1=0,\n",
        "                       l2=0,\n",
        "                       num_hidden=128):\n",
        "  regularizer = tf.keras.regularizers.l1_l2(l1, l2)\n",
        "\n",
        "  train_dataset = tf.data.TextLineDataset(\n",
        "      'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/train_set.csv'\n",
        "  ).map(decode_csv).batch(batch_size)\n",
        "\n",
        "  eval_dataset = tf.data.TextLineDataset(\n",
        "      'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/eval_set.csv'\n",
        "  ).map(decode_csv).batch(batch_size)\n",
        "\n",
        "  # Neural network with one hidden layer\n",
        "  model = tf.keras.Sequential([\n",
        "            tf.keras.layers.Flatten(input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)),\n",
        "            tf.keras.layers.Dense(units=num_hidden, kernel_regularizer=regularizer, activation='relu'),\n",
        "            tf.keras.layers.Dense(units=len(CLASS_NAMES),\n",
        "                                  kernel_regularizer=regularizer,\n",
        "                                  activation='softmax')\n",
        "  ])\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lrate),\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  history = model.fit(train_dataset, validation_data=eval_dataset, epochs=10)\n",
        "  training_plot(['loss', 'accuracy'], history)\n",
        "  \n",
        "  return model"
      ],
      "metadata": {
        "id": "SfH2WAj1Gt37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_and_evaluate(batch_size=32, lrate=0.0001, l1=0, l2=0, num_hidden=128)"
      ],
      "metadata": {
        "id": "XhtsmrRjGt7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_and_evaluate(batch_size=32, lrate=0.0001, l1=0, l2=0, num_hidden=256)"
      ],
      "metadata": {
        "id": "OdiJIWq8coHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regularisation"
      ],
      "metadata": {
        "id": "sCbaWdvcyzLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_and_evaluate(batch_size=32, lrate=0.0001, l1=0, l2=0.001, num_hidden=128)"
      ],
      "metadata": {
        "id": "6m7y8G3jc7Su"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Early stopping"
      ],
      "metadata": {
        "id": "eEG_Szxuy6Y3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regularizer = tf.keras.regularizers.l1_l2(0, 0.001)\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)),\n",
        "  tf.keras.layers.Dense(units=128, kernel_regularizer=regularizer, activation='relu'),\n",
        "  tf.keras.layers.Dense(len(CLASS_NAMES), kernel_regularizer=regularizer, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_dataset, validation_data=eval_dataset, epochs=10, callbacks=[tf.keras.callbacks.EarlyStopping(patience=1)])"
      ],
      "metadata": {
        "id": "ijMfGX02zB9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter tuning"
      ],
      "metadata": {
        "id": "lZzoXUxPdT5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q keras-tuner"
      ],
      "metadata": {
        "id": "EcukrG8qsem6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kerastuner as kt\n",
        "\n",
        "def build_model(hp):\n",
        "  lrate = hp.Float('lrate', 1e-4, 1e-1, sampling='log')\n",
        "  l1 = 0\n",
        "  l2 = hp.Choice('l2', values=[0.0, 1e-1, 1e-2, 1e-3, 1e-4])\n",
        "  num_hidden = hp.Int('num_hidden', 32, 256, 32)\n",
        "  \n",
        "  regularizer = tf.keras.regularizers.l1_l2(l1, l2)\n",
        "\n",
        "  # Neural network with one hidden layer\n",
        "  model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Flatten(\n",
        "            input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)),\n",
        "        tf.keras.layers.Dense(\n",
        "            units=num_hidden,\n",
        "            kernel_regularizer=regularizer,\n",
        "            activation='relu'),\n",
        "        tf.keras.layers.Dense(\n",
        "            units=len(CLASS_NAMES), \n",
        "            kernel_regularizer=regularizer,\n",
        "            activation='softmax')\n",
        "                              \n",
        "  ])\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lrate),\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "                metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_dataset = tf.data.TextLineDataset(\n",
        "    'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/train_set.csv'\n",
        ").map(decode_csv).batch(batch_size)\n",
        "\n",
        "eval_dataset = tf.data.TextLineDataset(\n",
        "    'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/eval_set.csv'\n",
        ").map(decode_csv).batch(batch_size)\n",
        "\n",
        "tuner = kt.BayesianOptimization(\n",
        "    build_model,\n",
        "    objective=kt.Objective('val_accuracy', 'max'),\n",
        "    max_trials=10,\n",
        "    num_initial_points=2,\n",
        "    overwrite=False) # True to start afresh\n",
        "\n",
        "tuner.search(\n",
        "    train_dataset, validation_data=eval_dataset,\n",
        "    epochs=5,\n",
        "    callbacks=[tf.keras.callbacks.EarlyStopping(\n",
        "        patience=1\n",
        "    )]\n",
        ")"
      ],
      "metadata": {
        "id": "HGUBkQCDsiGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get topN trials\n",
        "topN = 2\n",
        "for x in range(topN):\n",
        "  print(tuner.get_best_hyperparameters(topN)[x].values)\n",
        "  print(tuner.get_best_models(topN)[x].summary())"
      ],
      "metadata": {
        "id": "vidsS4rQMEYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building a DNN"
      ],
      "metadata": {
        "id": "r0eApP1pMFTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(batch_size=32, lrate=0.0001, l1=0, l2=0.001, num_hidden=[64, 16]):\n",
        "  regularizer = tf.keras.regularizers.l1_l2(l1, l2)\n",
        "\n",
        "  train_dataset = tf.data.TextLineDataset(\n",
        "      'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/train_set.csv'\n",
        "  ).map(decode_csv).batch(batch_size)\n",
        "\n",
        "  eval_dataset = tf.data.TextLineDataset(\n",
        "      'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/eval_set.csv'\n",
        "  ).map(decode_csv).batch(32) # Batch size for eval dataset doesn't matter\n",
        "\n",
        "  # NN with multiple hidden layers\n",
        "  layers = [\n",
        "    tf.keras.layers.Flatten(input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), \n",
        "                            name='input_pixels'),\n",
        "  ]\n",
        "  layers.append([\n",
        "    tf.keras.layers.Dense(nodes,\n",
        "                          kernel_regularizer=regularizer,\n",
        "                          activation='relu',\n",
        "                          name=f'hidden_dense_{hno}')\n",
        "  for hno, nodes in enumerate(num_hidden)])\n",
        "  layers.append([\n",
        "    tf.keras.layers.Dense(len(CLASS_NAMES),\n",
        "                          kernel_regularizer=regularizer,\n",
        "                          activation='softmax',\n",
        "                          name='flower_prob')\n",
        "  ])\n",
        "\n",
        "  model = tf.keras.Sequential(layers, name='flower_classification')\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lrate),\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossEntropy(\n",
        "                    from_logits=False),\n",
        "                metrics=['accuracy'])\n",
        "  print(model.summary())\n",
        "\n",
        "  history = model.fit(train_dataset, validation_data=eval_dataset, epochs=10)\n",
        "  training_plot(['loss', 'accuracy'], history)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "RCjYtHb_d8sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_and_evaluate(lrate=0.0001, l2=0.001, num_hidden=[64, 16])"
      ],
      "metadata": {
        "id": "tMbSowUGhz-3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}